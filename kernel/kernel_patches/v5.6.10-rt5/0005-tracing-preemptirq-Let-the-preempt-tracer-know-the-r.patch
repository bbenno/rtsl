From f6229c671f86ce4020d5ca61a8dfb8be05654409 Mon Sep 17 00:00:00 2001
Message-Id: <f6229c671f86ce4020d5ca61a8dfb8be05654409.1589812797.git.bristot@redhat.com>
In-Reply-To: <71e1b6cffa772a5839c4f175db4ad52e1fbec89d.1589812797.git.bristot@redhat.com>
References: <71e1b6cffa772a5839c4f175db4ad52e1fbec89d.1589812797.git.bristot@redhat.com>
From: Daniel Bristot de Oliveira <bristot@redhat.com>
Date: Wed, 22 Apr 2020 10:26:15 +0200
Subject: [PATCH 05/16] tracing/preemptirq: Let the preempt tracer know the
 reason why preemption was disabled

Foward the reason why the preemption was disabled to the preempt tracer.

No functional change.

Signed-off-by: Daniel Bristot de Oliveira <bristot@redhat.com>
---
 include/linux/ftrace.h          | 8 ++++----
 kernel/sched/core.c             | 4 ++--
 kernel/softirq.c                | 4 ++--
 kernel/trace/trace_preemptirq.c | 4 ++--
 4 files changed, 10 insertions(+), 10 deletions(-)

diff --git a/include/linux/ftrace.h b/include/linux/ftrace.h
index db95244a62d4..7345227ca749 100644
--- a/include/linux/ftrace.h
+++ b/include/linux/ftrace.h
@@ -802,15 +802,15 @@ static inline unsigned long get_lock_parent_ip(void)
 }
 
 #ifdef CONFIG_TRACE_PREEMPT_TOGGLE
-  extern void trace_preempt_on(unsigned long a0, unsigned long a1);
-  extern void trace_preempt_off(unsigned long a0, unsigned long a1);
+  extern void trace_preempt_on(unsigned long a0, unsigned long a1, int to_sched);
+  extern void trace_preempt_off(unsigned long a0, unsigned long a1, int to_sched);
 #else
 /*
  * Use defines instead of static inlines because some arches will make code out
  * of the CALLER_ADDR, when we really want these to be a real nop.
  */
-# define trace_preempt_on(a0, a1) do { } while (0)
-# define trace_preempt_off(a0, a1) do { } while (0)
+# define trace_preempt_on(a0, a1, to_sched) do { } while (0)
+# define trace_preempt_off(a0, a1, to_sched) do { } while (0)
 #endif
 
 #ifdef CONFIG_FTRACE_MCOUNT_RECORD
diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index 814c5bfbe200..ec5f54fafa73 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -3891,7 +3891,7 @@ static inline void preempt_latency_start(int val, int to_sched)
 #ifdef CONFIG_DEBUG_PREEMPT
 		current->preempt_disable_ip = ip;
 #endif
-		trace_preempt_off(CALLER_ADDR0, ip);
+		trace_preempt_off(CALLER_ADDR0, ip, to_sched);
 	}
 }
 
@@ -3934,7 +3934,7 @@ NOKPROBE_SYMBOL(preempt_count_add);
 static inline void preempt_latency_stop(int val, int to_sched)
 {
 	if (preempt_count() == val)
-		trace_preempt_on(CALLER_ADDR0, get_lock_parent_ip());
+		trace_preempt_on(CALLER_ADDR0, get_lock_parent_ip(), to_sched);
 }
 
 static inline void preempt_count_sub_debug(int val, int to_sched)
diff --git a/kernel/softirq.c b/kernel/softirq.c
index d975a066d47d..3c3bf45eb3a4 100644
--- a/kernel/softirq.c
+++ b/kernel/softirq.c
@@ -234,7 +234,7 @@ void __local_bh_disable_ip(unsigned long ip, unsigned int cnt)
 #ifdef CONFIG_DEBUG_PREEMPT
 		current->preempt_disable_ip = get_lock_parent_ip();
 #endif
-		trace_preempt_off(CALLER_ADDR0, get_lock_parent_ip());
+		trace_preempt_off(CALLER_ADDR0, get_lock_parent_ip(), 0);
 	}
 }
 EXPORT_SYMBOL(__local_bh_disable_ip);
@@ -245,7 +245,7 @@ static void __local_bh_enable(unsigned int cnt)
 	lockdep_assert_irqs_disabled();
 
 	if (preempt_count() == cnt)
-		trace_preempt_on(CALLER_ADDR0, get_lock_parent_ip());
+		trace_preempt_on(CALLER_ADDR0, get_lock_parent_ip(), 0);
 
 	if (softirq_count() == (cnt & SOFTIRQ_MASK))
 		trace_softirqs_on(_RET_IP_);
diff --git a/kernel/trace/trace_preemptirq.c b/kernel/trace/trace_preemptirq.c
index 4d8e99fdbbbe..077a348efe4e 100644
--- a/kernel/trace/trace_preemptirq.c
+++ b/kernel/trace/trace_preemptirq.c
@@ -78,14 +78,14 @@ NOKPROBE_SYMBOL(trace_hardirqs_off_caller);
 
 #ifdef CONFIG_TRACE_PREEMPT_TOGGLE
 
-void trace_preempt_on(unsigned long a0, unsigned long a1)
+void trace_preempt_on(unsigned long a0, unsigned long a1, int to_sched)
 {
 	if (!in_nmi())
 		trace_preempt_enable_rcuidle(a0, a1);
 	tracer_preempt_on(a0, a1);
 }
 
-void trace_preempt_off(unsigned long a0, unsigned long a1)
+void trace_preempt_off(unsigned long a0, unsigned long a1, int to_sched)
 {
 	if (!in_nmi())
 		trace_preempt_disable_rcuidle(a0, a1);
-- 
2.26.2

